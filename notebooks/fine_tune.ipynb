{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune a multiple choice NLP model\n",
    "\n",
    "Based on the [`transformers` multiple-choice fine tuning notebook](https://github.com/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb). Using \n",
    "pretrained `roberta-base` first, should work seamlessly with any other \n",
    "`AutoModelForMultipleChoice` from HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.32.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the MutualPlus dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset mutual_harness (/home/xqz-u/.cache/huggingface/datasets/lighteval___mutual_harness/mutual_plus/0.0.1/be31c67b35f0d5c4cce450a4e8475f0eb26ae243f5bfd701a524305282b0873a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68f91c301614e42b80bcb3f148a4c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answers', 'options', 'article', 'id'],\n",
       "        num_rows: 7088\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answers', 'options', 'article', 'id'],\n",
       "        num_rows: 886\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['answers', 'options', 'article', 'id'],\n",
       "        num_rows: 886\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "mutual_plus = load_dataset(\"lighteval/mutual_harness\", name=\"mutual_plus\")\n",
    "mutual_plus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answers': Value(dtype='string', id=None),\n",
       " 'options': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'article': Value(dtype='string', id=None),\n",
       " 'id': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_plus[\"train\"].features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answers': 'A',\n",
       " 'options': ['F: Although the suit you sew is the same as it, the material of this suit is imported from Italy.',\n",
       "  \"F: No suit has the same style as it. It's the style that makes it special. It is worth the price.\",\n",
       "  'F: I am afraid I did not quite catch what you were saying. Please repeat it.',\n",
       "  'F: But the color of our suit is very special.'],\n",
       " 'article': \"M: Excuse me. How much is this suit? F: It's on sale today for $750. It's normally $900. M: Wow, that is pretty expensive! I was thinking that it might be 4 or 500. F: This material is imported from Italy. It's the finest in the world, and if you bought a suit made of this material at many department stores, you would pay about $2000. M: Uh-hah. But isn't that the point of coming to a market like this, to get a discount compared to the expensive department stores? Besides I saw a suit just like this one a few stalls down, and they were selling it for $600. I still thought that it was too expensive.\",\n",
       " 'id': 'train_1'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = \"train\"\n",
    "mutual_plus[split][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We raname the `\"answers\"` column to `\"labels\"` as this is can be passed to a dataset collator (batch padding) and to a HF \n",
    "Transformer model, which usually accepts keyword arguments `input_ids`, `attention_mask` and `labels` (the latter for \n",
    "training).\n",
    "\n",
    "Moreover, if the `\"labels\"` column becomes a `ClassLabel`, then we have [numeric class labels](https://huggingface.co/docs/datasets/v2.14.5/en/package_reference/main_classes#datasets.Features) for free, so let's cast it. We can only do it on the `train` and `validation` splits \n",
    "though, as the `test` one only has empty labels as spaces `\" \"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/xqz-u/.cache/huggingface/datasets/lighteval___mutual_harness/mutual_plus/0.0.1/be31c67b35f0d5c4cce450a4e8475f0eb26ae243f5bfd701a524305282b0873a/cache-6ef2610c9e680d1e.arrow\n",
      "Loading cached processed dataset at /home/xqz-u/.cache/huggingface/datasets/lighteval___mutual_harness/mutual_plus/0.0.1/be31c67b35f0d5c4cce450a4e8475f0eb26ae243f5bfd701a524305282b0873a/cache-c595c1b4173c47da.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train {'labels': ClassLabel(names=['A', 'B', 'C', 'D'], id=None), 'options': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'article': Value(dtype='string', id=None), 'id': Value(dtype='string', id=None)}\n",
      "validation {'labels': ClassLabel(names=['A', 'B', 'C', 'D'], id=None), 'options': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'article': Value(dtype='string', id=None), 'id': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "source": [
    "from datasets import ClassLabel\n",
    "\n",
    "mutual_plus = mutual_plus.rename_column(\"answers\", \"labels\")\n",
    "for split in [\"train\", \"validation\"]:\n",
    "    mutual_plus[split] = mutual_plus[split].cast_column(\n",
    "        \"labels\", ClassLabel(num_classes=4, names=[\"A\", \"B\", \"C\", \"D\"])\n",
    "    )\n",
    "    print(split, mutual_plus[split].features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one_mutual(example: dict):\n",
    "    print(f\"Context: {example['article']}\")\n",
    "    for i, opt in enumerate(example[\"options\"]):\n",
    "        print(f\"  {i} - {opt}\")\n",
    "    print(f\"\\nGround truth: {gt if (gt := example['labels']) != ' ' else 'UNKNOWN'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 validation\n",
      "Context: F: Good morning. M: Morning. F: Come in, sit down. Now, you're a new patient, aren't you? M: Yes, that's right. F: Ok, so I better ask you some questions first. Now, have you ever had any serious illnesses or accidents? M: A broken leg I got from playing football when I was 17. I was in the school team at that time.\n",
      "  0 - F: So you broke your leg in a car accident when you were 15, right?\n",
      "  1 - F: When you were 15, a wild cat broke your leg? That's amazing.\n",
      "  2 - F: So you broke your leg when you were playing football, right?\n",
      "  3 - F: Just a minute! I do not quite follow what you are saying, would you mind repeating that?\n",
      "\n",
      "Ground truth: 2\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_idx = random.randint(0, mutual_plus[split].num_rows)\n",
    "print(random_idx, split)\n",
    "show_one_mutual(mutual_plus[split][random_idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the model: `roberta-base`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'classifier.weight', 'classifier.bias', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RobertaTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)}, clean_up_tokenization_spaces=True),\n",
       " RobertaForMultipleChoice(\n",
       "   (roberta): RobertaModel(\n",
       "     (embeddings): RobertaEmbeddings(\n",
       "       (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "       (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "       (token_type_embeddings): Embedding(1, 768)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (encoder): RobertaEncoder(\n",
       "       (layer): ModuleList(\n",
       "         (0-11): 12 x RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (pooler): RobertaPooler(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (activation): Tanh()\n",
       "     )\n",
       "   )\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       "   (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       " ))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForMultipleChoice\n",
    "\n",
    "model_checkpoint = \"roberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)\n",
    "tokenizer, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** Here we could remove speaker tags! Can be done\n",
    "1. Either before merging with selected datapoints from MMLU, or\n",
    "2. After merging, then regex must still work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "from transformers import PreTrainedTokenizerBase\n",
    "\n",
    "\n",
    "def preprocess_mutual(\n",
    "    datapoints: Dict[str, List[str]], tokenizer: PreTrainedTokenizerBase = None\n",
    ") -> Dict[str, List[List[List[int]]]]:\n",
    "    assert tokenizer is not None, f\"Need to pass a tokenizer as argument\"\n",
    "    n_options = len(datapoints[\"options\"][0])\n",
    "    # Repeat each context as many times along with each continuation\n",
    "    full_options = [\n",
    "        \" \".join([article, opt])\n",
    "        for article, options in zip(datapoints[\"article\"], datapoints[\"options\"])\n",
    "        for opt in options\n",
    "    ]\n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(full_options, truncation=True)\n",
    "    # Un-flatten\n",
    "    return {\n",
    "        k: [v[i : i + n_options] for i in range(0, len(v), n_options)]\n",
    "        for k, v in tokenized_examples.items()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function works with one or several examples. In the case of several \n",
    "examples, the tokenizer will return a list of lists of lists for each key: a \n",
    "list of all examples (here 5), then a list of all choices (4) and a list of \n",
    "input IDs (length varying here since we did not apply any padding).\n",
    "\n",
    "**NOTE** To correctly preprocess _only one_ datapoint,\n",
    "\n",
    "`preprocess_function(my_datapoints[:1], tokenizer=tokenizer)`.\n",
    "\n",
    "This way, the `datasets.DatasetDict` adds a layer of list to `my_datapoints` \n",
    "values and effectively batches them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'attention_mask']\n",
      "5 4 [165, 175, 165, 170]\n"
     ]
    }
   ],
   "source": [
    "example_features = preprocess_mutual(mutual_plus[split][:5], tokenizer=tokenizer)\n",
    "print(list(example_features))\n",
    "print(\n",
    "    len(example_features[\"input_ids\"]),\n",
    "    len(example_features[\"input_ids\"][0]),\n",
    "    [len(x) for x in example_features[\"input_ids\"][0]],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that that the tokenization was done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: F: Hi, Deck, would you like to go swimming this afternoon? M: I wish I could, but I have to spend the rest of the day in the library. I have a 10 page paper due tomorrow.\n",
      "  0 - F: Oh, are you going to the swiming pool? I have to go to library and study.\n",
      "  1 - F: I am afraid I did not quite catch what you were saying. Please repeat it.\n",
      "  2 - F: Great! Let's go to the swimming pool together this afternoon.\n",
      "  3 - F: Then I'll go to swimming pool without you. Enjoy your time at library.\n",
      "\n",
      "Ground truth: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<s>F: Hi, Deck, would you like to go swimming this afternoon? M: I wish I could, but I have to spend the rest of the day in the library. I have a 10 page paper due tomorrow. F: Oh, are you going to the swiming pool? I have to go to library and study.</s>',\n",
       " '<s>F: Hi, Deck, would you like to go swimming this afternoon? M: I wish I could, but I have to spend the rest of the day in the library. I have a 10 page paper due tomorrow. F: I am afraid I did not quite catch what you were saying. Please repeat it.</s>',\n",
       " \"<s>F: Hi, Deck, would you like to go swimming this afternoon? M: I wish I could, but I have to spend the rest of the day in the library. I have a 10 page paper due tomorrow. F: Great! Let's go to the swimming pool together this afternoon.</s>\",\n",
       " \"<s>F: Hi, Deck, would you like to go swimming this afternoon? M: I wish I could, but I have to spend the rest of the day in the library. I have a 10 page paper due tomorrow. F: Then I'll go to swimming pool without you. Enjoy your time at library.</s>\"]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_idx = 4\n",
    "show_one_mutual(mutual_plus[split][example_idx])\n",
    "[\n",
    "    tokenizer.decode(example_features[\"input_ids\"][example_idx][i])\n",
    "    for i in range(len(example_features[\"input_ids\"][example_idx]))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now tokenize the whole `MutualPlus`! \n",
    "\n",
    "**NOTE** We can differentiate tokenized datasets by caching them in different \n",
    "folders, there will be repetition but it's ok (the train split of MutualPlus is \n",
    "~21MB). E.g. `cache_dir/mutual_plus/train_sim_0.6`, `cache_dir/mutual_plus/train_rand_0.6`, \n",
    "`cache_dir/mutual_plus/train_nospeakers_sim_0.6` etc.\n",
    "\n",
    "**NOTE NOTE** No need to worry about file overriding, caching is performed properly automatically. This is true even \n",
    "across kernel restarts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/xqz-u/.cache/huggingface/datasets/lighteval___mutual_harness/mutual_plus/0.0.1/be31c67b35f0d5c4cce450a4e8475f0eb26ae243f5bfd701a524305282b0873a/cache-3e4280decfc9d40d.arrow\n",
      "Loading cached processed dataset at /home/xqz-u/.cache/huggingface/datasets/lighteval___mutual_harness/mutual_plus/0.0.1/be31c67b35f0d5c4cce450a4e8475f0eb26ae243f5bfd701a524305282b0873a/cache-d719d476f949c9a2.arrow\n",
      "Loading cached processed dataset at /home/xqz-u/.cache/huggingface/datasets/lighteval___mutual_harness/mutual_plus/0.0.1/be31c67b35f0d5c4cce450a4e8475f0eb26ae243f5bfd701a524305282b0873a/cache-5697a6235ea52fe6.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'options', 'article', 'id', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 7088\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'options', 'article', 'id', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 886\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'options', 'article', 'id', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 886\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from similarity_augmentation import conf\n",
    "\n",
    "# mutualplus_tokenized_cache = conf.TOKENIZED_DATASET_DIR / \"mutual_plus\"\n",
    "# mutualplus_tokenized_cache.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# NOTE no need to tokenize the test set too, but I'm lazy and it's only 2.6MB\n",
    "tokenized_mutualplus = mutual_plus.map(\n",
    "    preprocess_mutual,\n",
    "    batched=True,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    # cache_file_names={k: str(mutualplus_tokenized_cache / k) for k in mutual_plus},\n",
    ")\n",
    "tokenized_mutualplus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** `input_ids` and `attention_mask` are now added to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even better, the results are automatically cached by the `datasets` library to \n",
    "avoid spending time on this step the next time you run your notebook. The \n",
    "`datasets` library is normally smart enough to detect when the function you pass\n",
    "to map has changed (and thus requires to not use the cache data). For instance, \n",
    "it will properly detect if you change the task in the first cell and rerun the \n",
    "notebook. `datasets` warns you when it uses cached files, you can pass \n",
    "`load_from_cache_file=False` in the call to `map` to not use the cached files \n",
    "and force the preprocessing to be applied again.\n",
    "\n",
    "Note that we passed `batched=True` to encode the texts by batches together. This\n",
    "is to leverage the full benefit of the fast tokenizer we loaded earlier, which \n",
    "will use multi-threading to treat the texts in a batch concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that dynamically pads the inputs for multiple choices received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[str, List[List[int]]]]]):\n",
    "        labels = [feature.pop(\"labels\") for feature in features]\n",
    "        batch_size, num_choices = len(features), len(features[0][\"input_ids\"])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)]\n",
    "            for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels under a key accepted by model()\n",
    "        return batch | {\"labels\": torch.tensor(labels, dtype=torch.int64)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When called on a list of examples, it will flatten all the inputs/attentions masks etc. in big lists that it will pass to the `tokenizer.pad` method. This will return a dictionary with big tensors (of shape `(batch_size * 4) x seq_length`) that we then unflatten.\n",
    "\n",
    "We can check this data collator works on a list of features, we just have to make sure to remove all features that are not inputs accepted by our model (something the `Trainer` will do automatically for us after):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 4, 301]), torch.Size([10]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "example = [\n",
    "    {k: v for k, v in tokenized_mutualplus[split][i].items() if k in accepted_keys}\n",
    "    for i in range(10)\n",
    "]\n",
    "example_batch = DataCollatorForMultipleChoice(tokenizer=tokenizer)(example)\n",
    "example_batch[\"input_ids\"].shape, example_batch[\"labels\"].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: M: Good morning, I'd like to buy a cake. F: No problem sir, we have many cakes here, what size would you like? M: Well, it's for my coworker's birthday, there are 14 people in the office. F: Well, this cake feeds 12 people and this one behind it feeds 20. M: I'll take the bigger one, it's better to have too much than not enough. F: Sounds good, do you want it delivered? M: Yes. Can you deliver it to my office? The birthday party will be after work at a park near the office.\n",
      "  0 - F: Sure. Hope you enjoy the party in the park. Have a nice day.\n",
      "  1 - F: No problem. I'll send the cake to the park you asked me to do.\n",
      "  2 - F: Sure, hope you have fun during the party at the office.\n",
      "  3 - F: Just a minute! I do not quite follow what you are saying, would you mind repeating that?\n",
      "\n",
      "Ground truth: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"<s>F: Hey Mike, over here. M: Hi, it's great to see you, been waiting long? F: No, not at all. What do you want to have? M: Just a salad, so how's the new apartment working out? F: Good, I like it. The neighborhood, though, is... Well, some of the buildings down the street are covered with terrible pictures drawn by teenagers. M: I know what you mean. I think we need to report people who are drawing to the police. F: Yes, and I like all the stores. It's convenient for shopping, and it's pretty quiet at night. That's definitely a plus. M: Sounds like you're pretty satisfied. F: Yeah, I guess so, uh the only problem is that it's impossible to find parking. I have to drive around the block 6 or 7 times to find a space, usually I can't find a space usually I can find one, but sometimes I have to park really far away. M: Well, is there anyway, you can rent space in a garage. F: Yeah, that's a good idea. So now are things in your neighborhood. M: There's a bit of noise problem where I live. I live right down the street from a school. The bell rings every morning at 7:30, it's impossible to sleep in. F: Oh, you live near a school. That must be noisy.</s><pad><pad>\",\n",
       " \"<s>F: Hey Mike, over here. M: Hi, it's great to see you, been waiting long? F: No, not at all. What do you want to have? M: Just a salad, so how's the new apartment working out? F: Good, I like it. The neighborhood, though, is... Well, some of the buildings down the street are covered with terrible pictures drawn by teenagers. M: I know what you mean. I think we need to report people who are drawing to the police. F: Yes, and I like all the stores. It's convenient for shopping, and it's pretty quiet at night. That's definitely a plus. M: Sounds like you're pretty satisfied. F: Yeah, I guess so, uh the only problem is that it's impossible to find parking. I have to drive around the block 6 or 7 times to find a space, usually I can't find a space usually I can find one, but sometimes I have to park really far away. M: Well, is there anyway, you can rent space in a garage. F: Yeah, that's a good idea. So now are things in your neighborhood. M: There's a bit of noise problem where I live. I live right down the street from a school. The bell rings every morning at 7:30, it's impossible to sleep in. F: I didn’t hear you. Please could you tell me again?</s>\",\n",
       " \"<s>F: Hey Mike, over here. M: Hi, it's great to see you, been waiting long? F: No, not at all. What do you want to have? M: Just a salad, so how's the new apartment working out? F: Good, I like it. The neighborhood, though, is... Well, some of the buildings down the street are covered with terrible pictures drawn by teenagers. M: I know what you mean. I think we need to report people who are drawing to the police. F: Yes, and I like all the stores. It's convenient for shopping, and it's pretty quiet at night. That's definitely a plus. M: Sounds like you're pretty satisfied. F: Yeah, I guess so, uh the only problem is that it's impossible to find parking. I have to drive around the block 6 or 7 times to find a space, usually I can't find a space usually I can find one, but sometimes I have to park really far away. M: Well, is there anyway, you can rent space in a garage. F: Yeah, that's a good idea. So now are things in your neighborhood. M: There's a bit of noise problem where I live. I live right down the street from a school. The bell rings every morning at 7:30, it's impossible to sleep in. F: So you live near a school and it's quiet, right?</s><pad><pad>\",\n",
       " \"<s>F: Hey Mike, over here. M: Hi, it's great to see you, been waiting long? F: No, not at all. What do you want to have? M: Just a salad, so how's the new apartment working out? F: Good, I like it. The neighborhood, though, is... Well, some of the buildings down the street are covered with terrible pictures drawn by teenagers. M: I know what you mean. I think we need to report people who are drawing to the police. F: Yes, and I like all the stores. It's convenient for shopping, and it's pretty quiet at night. That's definitely a plus. M: Sounds like you're pretty satisfied. F: Yeah, I guess so, uh the only problem is that it's impossible to find parking. I have to drive around the block 6 or 7 times to find a space, usually I can't find a space usually I can find one, but sometimes I have to park really far away. M: Well, is there anyway, you can rent space in a garage. F: Yeah, that's a good idea. So now are things in your neighborhood. M: There's a bit of noise problem where I live. I live right down the street from a school. The bell rings every morning at 7:30, it's impossible to sleep in. F: Well, although your neighbor is dirty, it's quiet.</s><pad><pad><pad>\"]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_one_mutual(tokenized_mutualplus[\"train\"][8])\n",
    "[\n",
    "    tokenizer.decode(example_batch[\"input_ids\"][8][i].tolist())\n",
    "    for i in range(len(example_batch[\"input_ids\"][8]))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[165, 205, 87, 129, 69, 98, 134, 222, 299, 97]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"<s>M: Hello, is this doctor, Smith's office? F: Yes, it is. May I help you? M: Yes, I'd like to speak to doctor Smith, please? F: Doctor Smith went home this afternoon. May I ask who is calling? M: This is Jim White. F: Please wait a second. I'll get Dr. Smith for you. He is right in his office.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\",\n",
       " \"<s>M: Hello, is this doctor, Smith's office? F: Yes, it is. May I help you? M: Yes, I'd like to speak to doctor Smith, please? F: Doctor Smith went home this afternoon. May I ask who is calling? M: This is Jim White. F: I am afraid I did not quite catch what you were saying. Please repeat it.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\",\n",
       " \"<s>M: Hello, is this doctor, Smith's office? F: Yes, it is. May I help you? M: Yes, I'd like to speak to doctor Smith, please? F: Doctor Smith went home this afternoon. May I ask who is calling? M: This is Jim White. F: OK. Dr. Smith is at his home now. You can try tomorrow.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\",\n",
       " \"<s>M: Hello, is this doctor, Smith's office? F: Yes, it is. May I help you? M: Yes, I'd like to speak to doctor Smith, please? F: Doctor Smith went home this afternoon. May I ask who is calling? M: This is Jim White. F: OK. Dr. Smith is in his office now. I'll let him know you called when he gets home.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\"]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print([len(el[0]) for el in tokenized_mutualplus[split][:10][\"input_ids\"]])\n",
    "# article + option longest are at indces 2 and 3; still I don't know why the\n",
    "# longest sequence is padded to 214 and not left at 210\n",
    "[\n",
    "    tokenizer.decode(example_batch[\"input_ids\"][2][i].tolist())\n",
    "    for i in range(len(example_batch[\"input_ids\"][3]))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluation, `transformers.Trainer` passes an instance of \n",
    "[`transformers.trainer_utils.EvalPrediction`](https://github.com/huggingface/transformers/blob/b71f20a7c9f3716d30f6738501559acf863e2c5c/src/transformers/trainer_utils.py#L108) \n",
    "to the function passed to the `Trainer` by the parameter `compute_metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers.trainer_utils import EvalPrediction\n",
    "\n",
    "\n",
    "def compute_metrics_fn(eval_predictions: EvalPrediction) -> Dict[str, float]:\n",
    "    # NOTE loss gets included automatically\n",
    "    predictions, labels = eval_predictions\n",
    "    if len(labels.shape) < 2:\n",
    "        # add batch dimension to labels if necessary\n",
    "        labels = labels[..., None]\n",
    "    ranked_predictions = np.argsort(-predictions)\n",
    "    # since we only have 4 ranks, compute until R@3 (at 4 is always 1.0)\n",
    "    recalls = (ranked_predictions == labels).astype(np.float32)\n",
    "    mean_recalls_at = recalls.mean(0)\n",
    "    recalls_dict = {\n",
    "        f\"R@{k}\": mean_recalls_at[:k].sum().item()\n",
    "        for k in range(1, len(mean_recalls_at))\n",
    "    }\n",
    "    inverse_ranks = 1 / (np.argwhere(ranked_predictions == labels)[:, 1] + 1)\n",
    "    return recalls_dict | {\"MRR\": inverse_ranks.mean().item()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the implemented metrics: recalls at increasing positions should be \n",
    "monotonically increasing, and higher recalls at lower positions should yield \n",
    "higher MRR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden labels: [2 3 1 2 1]\n",
      "Ranked predictions:\n",
      "[[3 1 0 2]\n",
      " [3 0 1 2]\n",
      " [1 3 0 2]\n",
      " [0 2 1 3]\n",
      " [3 2 1 0]]\n",
      "Evaluation: {'R@1': 0.4000000059604645, 'R@2': 0.6000000238418579, 'R@3': 0.800000011920929, 'MRR': 0.6166666666666667}\n",
      "-------\n",
      "Golden labels: [0 1 2 0 2]\n",
      "Ranked predictions:\n",
      "[[1 2 0 3]\n",
      " [0 3 2 1]\n",
      " [1 2 0 3]\n",
      " [2 1 3 0]\n",
      " [1 2 0 3]]\n",
      "Evaluation: {'R@1': 0.0, 'R@2': 0.4000000059604645, 'R@3': 0.6000000238418579, 'MRR': 0.36666666666666664}\n",
      "-------\n",
      "Golden labels: [2 0 3 1 3]\n",
      "Ranked predictions:\n",
      "[[0 3 1 2]\n",
      " [2 3 1 0]\n",
      " [2 0 1 3]\n",
      " [2 1 0 3]\n",
      " [2 0 3 1]]\n",
      "Evaluation: {'R@1': 0.0, 'R@2': 0.20000000298023224, 'R@3': 0.4000000059604645, 'MRR': 0.31666666666666665}\n",
      "-------\n",
      "Golden labels: [3 0 0 3 0]\n",
      "Ranked predictions:\n",
      "[[1 0 3 2]\n",
      " [0 1 2 3]\n",
      " [3 2 0 1]\n",
      " [3 0 2 1]\n",
      " [3 1 2 0]]\n",
      "Evaluation: {'R@1': 0.4000000059604645, 'R@2': 0.4000000059604645, 'R@3': 0.800000011920929, 'MRR': 0.5833333333333333}\n",
      "-------\n",
      "Golden labels: [0 3 1 3 0]\n",
      "Ranked predictions:\n",
      "[[1 3 0 2]\n",
      " [1 3 2 0]\n",
      " [1 0 3 2]\n",
      " [1 0 3 2]\n",
      " [3 1 0 2]]\n",
      "Evaluation: {'R@1': 0.20000000298023224, 'R@2': 0.4000000059604645, 'R@3': 1.0, 'MRR': 0.5}\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "for _ in range(5):\n",
    "    evalpred = EvalPrediction(np.random.rand(n, 4), np.random.randint(0, 4, (n,)))\n",
    "    print(f\"Golden labels: {evalpred.label_ids}\")\n",
    "    print(f\"Ranked predictions:\\n{np.argsort(-evalpred.predictions)}\")\n",
    "    print(f\"Evaluation: {compute_metrics_fn(evalpred)}\")\n",
    "    print(\"-------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments(\n",
      "_n_gpu=0,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.EPOCH,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=finetuned_models/roberta-base-finetuned-mutualplus/runs/Oct05_03-04-03_stern,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "output_dir=finetuned_models/roberta-base-finetuned-mutualplus,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=16,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=finetuned_models/roberta-base-finetuned-mutualplus,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "from similarity_augmentations import conf\n",
    "\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "batch_size = 16  # this is copied from the example notebook, try other values\n",
    "\n",
    "args = TrainingArguments(\n",
    "    conf.FINETUNED_MODELS_DIR / f\"{model_name}-finetuned-mutualplus\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    # push_to_hub=True,\n",
    ")\n",
    "print(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_mutualplus[\"train\"],\n",
    "    eval_dataset=tokenized_mutualplus[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "    compute_metrics=compute_metrics_fn,\n",
    ")\n",
    "trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, to the \"fun\" stuff: mixing the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's get the MMLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset mmlu (/home/xqz-u/.cache/huggingface/datasets/cais___mmlu/all/1.0.0/1f5be36877bf67bdc9a548113a281aec5730e14ead069b31cb63971b9fab210d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbd12ab7c9342e6b838e0631b83617e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    auxiliary_train: Dataset({\n",
       "        features: ['question', 'subject', 'choices', 'answer'],\n",
       "        num_rows: 99842\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'subject', 'choices', 'answer'],\n",
       "        num_rows: 14042\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'subject', 'choices', 'answer'],\n",
       "        num_rows: 1531\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['question', 'subject', 'choices', 'answer'],\n",
       "        num_rows: 285\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmlu = load_dataset(\"cais/mmlu\", name=\"all\")\n",
    "mmlu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea is to insert specific datapoints of MMLU inside MuTual with the same features, so that the same preprocessing, \n",
    "`DataCollator` and fine tuning code for bare MuTual applies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Tuple\n",
    "\n",
    "from datasets import concatenate_datasets, Dataset\n",
    "\n",
    "\n",
    "def unify_datasets_structure(\n",
    "    mutual_split: Dataset, mmlu_split: Dataset\n",
    ") -> Tuple[Dataset, Dataset]:\n",
    "    # drop some unused columns\n",
    "    if \"subject\" in mmlu_split.features:\n",
    "        mmlu_split = mmlu_split.remove_columns(\"subject\")\n",
    "    if \"id\" in mutual_split.features:\n",
    "        mutual_split = mutual_split.remove_columns(\"id\")\n",
    "    # 'labels' is used by HF transformers for ground truth\n",
    "    if \"labels\" not in mutual_split.features and \"answers\" in mutual_split.features:\n",
    "        mutual_split = mutual_split.rename_column(\"answers\", \"labels\")\n",
    "    # normalize the feature names to MuTual's ones\n",
    "    to_mutual_map = {\"answer\": \"labels\", \"choices\": \"options\", \"question\": \"article\"}\n",
    "    mmlu_split = mmlu_split.rename_columns(to_mutual_map)\n",
    "    # answer values are the same, but for MMLU is different dtype, make compatible\n",
    "    mutual_split = mutual_split.cast_column(\"labels\", mmlu_split.features[\"labels\"])\n",
    "    return mutual_split, mmlu_split\n",
    "\n",
    "\n",
    "def merge_mmlu_in_mutual(\n",
    "    mutual_split: Dataset, mmlu_split: Dataset, mmlu_merge_ids: Iterable[int]\n",
    ") -> Dataset:\n",
    "    mutual_split, mmlu_split = unify_datasets_structure(mutual_split, mmlu_split)\n",
    "    return concatenate_datasets([mutual_split, mmlu_split.select(mmlu_merge_ids)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that it works: the desired MMLU datapoits are appended to MuTual.\n",
    "\n",
    "**NOTE** So it's important that the dataset is appropriately shuffled during \n",
    "training! And [it is](https://github.com/huggingface/transformers/blob/03af4c42a624ea44b3325ff78151f499392dd617/src/transformers/trainer.py#L796C23-L796C23).\n",
    "\n",
    "**NOTE NOTE** This is basically the _random_ selection strategy for data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/xqz-u/.cache/huggingface/datasets/lighteval___mutual_harness/mutual_plus/0.0.1/be31c67b35f0d5c4cce450a4e8475f0eb26ae243f5bfd701a524305282b0873a/cache-66c4dec026cd72f2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56038 60079 37144 91169 71811 58972 30662 14701 63317 88102]\n",
      "{'question': ['Researchers in London and Bristol have found that men are particularly likely to yield to depression if their partners are also depressed. The finding highlights the importance of paying attention to the partners of depressed mothers, as young children themselves are vulnerable   to social problems if both parents are depressed. Researchers in London and at the University of Bristol launched their study to investigate whether family structure affects the likelihood of depression in men around the time their child is born. They looked at men from traditional families, men with children from a previous relationship, men whose partners had children by a former partner, and men who were not living with their partners. All 7,108 participants filled out a questionnaire on depression, and answered questions about their age, education level and employment status. Details about the quality of their relationships with their partners, networks of friends and previous life events were also recorded. About 3.5 percent of the men and 13 percent of their partners suffered depression around the time their child was born. While men in stepfamilies or who were not living with their partners were twice as likely to get depressed as those in traditional families, this could be explained by other factors that are more common in nontraditional families, such as poor education and relationship conflicts. Even allowing for all these factors, however, the partners of women who were suffering from prenatal   depression were significantly more likely to become depressed themselves, the researchers report in an American journal. Ten percent of women who were depressed had depressed partners. For the healthy women, the figure was only 2.6 percent. Previous research suggests that families with two depressed parents may need special attention. A researcher in Atlanta has found that primary school children with two troubled parents have difficulty relating to their peers. \"It\\'s extremely important to look at the whole family.\" she says. According to the passage, which of the following statements is NOT true?', \"Don't go to Kauai. Go to any of the other Hawaiian Islands--Maui, Lanai, the Big Island-- but leave Kauai for us. The weather on Kauai is so unpredictable that sometimes it rains all day--in fact, it's the second-wettest spot on the earth. Yes, there are giant double rainbows all the time, and the sunlight through the clouds is magical. But if you are not interested in these, go somewhere else. You just can't control the nature on Kauai, and who wants to surrender   to the nature when you could be at a fine hotel, lying in a comfortable chair next to a swimming pool, with food served upon request?        So what if Kauai produces surf champions the wayprefix = st1 /Texasproduces cowboys? Most of its 300 white-sand beaches are unmarked. Unless you connect with the local people, the hidden spots are hard to find. While Hanalei is the most beautiful town you've ever dreamed of, you can forget about discos and clubs. Worse, it doesn't have one single four-star restaurant. What it does have is the original drive-through places where you pass by a rambutan tree, and pick a piece of fruit.        Shopping in Kauai? Forget it--unless you are interested in shell necklaces and beautifully carved wood bowls. Kauai is not about pampering. It's about going natural and finding the nature within you. It's a do-it-yourself place that offers walking along the coast, diving and swimming in the Pacific Ocean, and lying on the beach.        Don't go to Kauai unless you have a lot of time, because there's only one road, which can be slightly dull. It winds through the beautiful scenery of waterfalls, rivers flowing into the ocean, and taro fields. You have no choice but to look at everything, because the speed limit is 35 m.p.h.        If you're not interested in color1, don't bother with Kauai, because that's what you get--red roads, blue oceans, and a hundred different shades of green. It's like diving on land. Many people on Kauai believe that this is Lemuria--a lost island in the Atlantic. Can you imagine? Those Hawaiians, surfers, New Agers, and people who love nature and beauty and want a different quality of life--what do they know, anyway? Forget about it--you're not going to like it. Go somewhere else. Leave Kauai for us. Who would like to visit Kauai?\", 'Heather Jack and her family, including her two children, usually spend the Christmas holidays preparing a feast--for others to eat. Last Christmas Eve, they went to a house in the neighborhood and prepared a dinner for an elderly woman and her son, who has muscular dystrophy . They stayed for an hour and chatted before heading home to prepare for a visit from Santa  .  \"I think it is that kind of direct experience that many find so meaningful,\" says Heather, president and founder of The Volunteer Family, a Boston-based organization dedicated to matching families with volunteer opportunities, both during the holidays and year-round. \"It\\'s a great way for parents to involve the kids.\" In a holiday season that stretches from before Thanksgiving to just after the New Year, it\\'s nice to hear stories about people with their children giving instead of receiving. Last December Gary and Debra Danoff and their two teenage sons drove to the Washington, D. C. Jewish Community Center(JCC) and spent Christmas morning in the Center\\'s kitchen preparing a feast for homeless shelters.  By choosing to prepare meals for the homeless, the Danoffs bring together a belief in community service with their love of cooking, \"It feels good to prepare food with our kids for other people at Christmas,\" says Gary. \"We want them to know that many people don\\'t have the ability to go to the supermarket and pick the foods they want to eat and pay for them.\" The Danoffs were in good company. Across the city, at least 1000 volunteers with their children went across the region to provide food to the poor people as part of the D. C. JCC\\'s annual \"December 25th Day of Service\", now in its 22nd year. The Heathers did all the following things except_last Christmas Eve.', \"Monday, April 17 Dear Gramps, I was so upset last week when somebody stole my Super Racer from the park by your house. I called up the toy company but they said they have only red, blue and green racers. Dad called Cobb's Toy Store today and found out they might have purple ones. Can we go there when I come to visit you next week?You and I were only gone for a few minutes to the shop down the street to get ice-cream and cookies. Maybe the thief was watching us. Mum was surprised when I told her the racer was stolen. She said she used to leave things at the park all the time when she was young. Once she even left her bicycle for two days near the swimming pool. Tell Grandma that I like the food she made last time. Ask Grandma if we can have pancakes with sugar for breakfast when I come this time. I have packed in my towel, comb and soap. Tell her this time I won't forget to pack in my toothbrush. Love Toby The writer wants to have a   _   racer.\", \"On a cold winter day, a fox told Mother Bear that he would teach her how to fish. For she wanted to learn, he took her to a hole in the ice, and told her to put her tail  down into the water. He told her to keep the tail there for a long time. Then when she pulled the tail out of the water, she would find fish around the tail. The bear was foolish enough to believe what the fox said. She sat for a long time with her tail in the water. She was waiting for the fish. But when she tried to pull her tail out of the water she found that it was frozen  in the ice. She asked the fox to pull her out, but the fox laughed to itself and ran away. So she called Father Bear to help her. Father Bear came. He pulled her hard and at last got her out. But a part of her tail was in the ice. That is why people find the bear's tail so short. What did a fox tell Mother Bear to do on a cold winter day?\", 'Tens of thousands of ancient pictures carved into the rocks at one of France\\'s most important tourist sites are being gradually destroyed. Scientists and researchers fear that the 36,000 drawings on rocks in Mont Bego in the French Alps are being damaged so rapidly that they will not survive for future generations. The mountain, believed to have once been a site for prayer, is scattered   with 4,000-year-old drawings cut into bare rock. They include pictures of cows with horns, cultivated fields   and various gods and goddesses. But as the popularity of the site increases, the pictures are being ruined by thoughtless graffiti  . Jean Clottes is the chairman of the International Committee on Rock Art. He says, \"People think that because the pictures have been there so long they will always continue to be there. But if the damage continues at this rate there will be nothing left in 50 years.\" He describes seeing tourists stamping on the drawings, wearing away the rock and definition   of the artwork as they do so. Some visitors, he says, even cut off parts to take home as souvenirs. \"When people think they can\\'t take a good enough photograph, they rub the drawings to get a clearer picture,\" he said. \"The drawings are polished by the weather, and if the sun is shining and the visitors can\\'t see them properly they simply rub them to make them look fresher.\" Other researchers describe how people arrive carrying long sticks with sharp ends to scratch   their own drawings, or even their names, in the rocks. But experts are divided over the best way to preserve the drawings. Henry de Lumley, director of the Museum of Natural History in Paris, believes that the only way to save the site is to turn the whole mountain into a \"no-go\" area, preventing the public from going there except on guided tours. Otherwise, he says, not only will the site be completely destroyed but important research work will be reduced. Clottes disagrees, \"The measure suggested by Henry de Lumley is the most severe, and while it is the most effective, it is also certain to bring about protests from people who live there,\" he said. \"The site was classified as a historic monument years ago by the Ministry of Culture, and we must do as much as possible to save what is there.\" David Lavergne, the regional architect, also wants to avoid closing the site. \"Henry de Lumley\\'s idea isn\\'t ideal,\" he said. \"Our department feels that the best solution is to let people look at the site, but because the area is very big it is difficult to prevent visitors from damaging it. I would prefer that everyone was able to look at it, but the main problem is money. We do not have the funds to employ the necessary number of guards. We may have to consider charging a fee. It doesn\\'t seem to be possible to get the government support.\" In Nice, Annie Echassoux, who also worked on researching the site, is alarmed that as the mountain becomes easier to reach -- tourists can now avoid the three-and-a-half-hour walk by hiring vehicles -- the damage will increase rapidly. She thinks that the only solution is to rope off the area and provide guides. \"You can\\'t say the plan can\\'t go ahead because there is no money,\" she said. \"That is not good enough. Money must be provided because the Ministry of Culture has classified this area as a historic site. If we don\\'t take steps, we will be responsible for losing the drawings for the next generation.\" Jean Clottes says that people who visit the mountain  _  .', \"They say love can cover a lot of crimes; yet never have I seen it more beautifully showed than in the life of a dog named Jessie. Jessie came into our lives at the age of six months. By that time he had already experienced the hard knocks of life. He was found abandoned on the side of the road, where we adopted him and took him home. From the beginning, it was obvious that Jessie was traumatized  . He was afraid of everything: the car, the doors, the stairs, and just about everything else. We couldn't foresee where Jessie's fear would take us. Jessie was with us for about six months, when we became foster parents to a mixed-breed young dog. Jessie did not like her at all. We all lived in a nervous co-existence, until dinnertime. Within moments a food fight erupted between Jessie and this foster child. It all happened so fast, and I was in the middle. My husband managed to get in between the two dogs, grabbing Jessie by his collar. Jessie screamed all the way down the hall and into the bedroom. I, quickly put the foster dog into her own bedroom and hurried down the hall. The crashing I heard in the bedroom, scared me to death. But nothing prepared me for the scene I witnessed as I opened the bedroom door. There was my husband, on top of a terrified Jessie, holding back his head. Blood dripped from my husband's arm. To tell you the truth, as I was sitting beside my husband in the emergency room, I just didn't know what to do with Jessie. I was so angry at that dog. Day after day, week after week, however, my husband faithfully trained the dog that others would have put down. As his arm healed over the next months, something rare and beautiful began to take place. Jessie, under my husband's gentle persuasion, began to understand and obey. And Jessie adored him. I could see, that although the tempest had ruled Jessie's former life, affirmation and love had calmed the storm. What would be the best title for the text?\", 'The art of reading fiction is largely a matter of inferring meanings. To infer means to understand facts which are not directly stated---only suggested. Inference is one of the commonest ways of knowing things: a child holds his knee and cries; this action implies his feeling; an observer infers that the child is hurt. To infer accurately in everyday life requires caution in observing; to infer skillfully in fiction requires caution in reading; both require disciplined imagination. The short-story reader can expect to find certain basic elements in any story. For example, all stories involve a person or persons, in a particular setting, faced with a demand for a response. The response called for may be a physical action, such as defeating an adversary  or escaping from a danger; or it may be a mental action, such as adjusting to others or within oneself. In either case, the short story is a description in two ways: first, it shows the motives for a given human action; second, it makes a point about the general human situation. Such descriptions, however, rather than being stated directly, usually are implied by the elements of the story. When the reader of a story understands all the facts and their interrelationships, he is ready to infer the significance of the story as a whole---its comment on the human situation. This comment, or theme, is the seed from which the story grew. It is also the idea by which all the separate elements of the story are governed, while these in turn further shape and modify the theme. In addition to action, character, and setting, these elements include structure, mood, tone, and point of view. Fiction reading requires an awareness of all the ways in which a story communicates. It also requires attention to detail. What the author provides is a network of points which serve as clues to his meaning. He invites the reader to develop the meaning by inference, actually to create much of the story himself and so make it part of his own experience. What is inferring in fiction based on?', \"My parents always raised me to have strong values and hold firm to my confidence in life, and this was never more proved than when a situation arose when it would be easy for most people to ignore it. A gentleman at my father's work smelled awful and neglected his behavior, and as the months went by, he showed signs of confusion. After being told to pick up papers at another building, he would be found sitting at his desk staring at his shoes; after being reminded (to which he would completely believe he hadn't been told the first time), he would be found once again sitting at his desk in the same position. This happened to worsening degrees over a few months and his coworkers either ignored it or were ignorant to this due to a lack of social association with the man. My father began to mentally record all of this and finally sat down with him one day when he was found two hours after work was out, sitting in his car, looking like he didn't know where to go. Apparently the gentleman was in the beginning/middle stages of Alzheimer's and there was someone who used his forgetfulness as a reason to ask him for money every few days. My father took this man to a hospital (for the first time in years) to be properly treated, and then got a caretaker to watch over his condition. He then went to the man's house and helped him sort out all of his financial matters and get his retirement set up; they went to the bank and had a government worker ensure that his bills would be paid for and his children would no longer get to treat him like a personal ATM. That my father took his much personal time to help another man that so many had forgotten or would choose to neglect, or even make fun of, truly shows his character. In the eyes of the author, his father is   _  .\", 'There are some very good inventions which, for one reason or another, don\\'t become popular. These inventions should be better known, even though I think that some of them are crazy. Let\\'s have a look at some of these inventions and see if you agree that they should be more successful. The Australians had a great idea to stop people from drinking and driving. The idea was that if a driver wanted to start the car, she or he would have to blow into a bag first. If there was too much alcohol   in their breath, the car wouldn\\'t start. It sounded like a great idea to me, but people said that they might need to drive the car in an emergency   even if they had drunk too much alcohol. Another idea I liked was an invention by a scientist who thought his children watched too much TV. He connected the TV to an exercise bike so that the electricity to power the TV was produced by the bike. If the children wanted to watch a lot of TV, they had to pedal   very hard. I found another invention on the Internet which encouraged good habits. Believe it or not, this invention was an ashtray   which spoke to you when you lit a cigarette! The \"voice\" of the ashtray was started by the heat from the cigarette and reminded you how dangerous it is to smoke. One of the strangest inventions I have come across is a bicycle which can cross rivers! The idea was that when you came to a river, you could _ a huge plastic ball all around the bike. You would then get into the ball which would float on the river while you pedaled the bike inside the ball! Why not use a bridge instead? A friend of mine at school once bought a strange pair of football shoes. On the bottom of the shoes there was a rotating pad of studs  . The idea was that you would change direction more quickly if the studs rotated with you. The problem was that every time you stopped you changed direction whether you wanted to or not! I think he wore those shoes twice! One thing I would like is a baseball cap with a built-in radio so you can listen to sport all day with your hands free. While we are on the subject of sport, the Americans invented a kind of robot for sports fans. If you were watching your team on TV on your own, you could press a button and the robot would do \"high fives\" with you! Fantastic! I wonder if you have any good ideas for inventions like these. What can we know from the passage?'], 'subject': ['', '', '', '', '', '', '', '', '', ''], 'choices': [['Ten percent of women who were depressed had depressed partners.', '2.6 percent of healthy women were depressed.', 'Special attention should be paid to families in which both the father and the mother were depressed.', \"Primary school children whose parents were both depressed couldn't get along well withtheir peers.\"], ['Those who love nature.', 'Those who love city life.', 'Those who love the comfort in a fine hotel.', 'Those who love going shopping.'], ['preparing a dinner for a poor family', 'chatting with the elderly mother and her disabled son', 'making preparations for their own Christmas festival', 'visiting one of their good friends in other district'], ['red', 'blue', 'green', 'purple'], ['It told her to swim in the lake.', 'It told her to play by the lake.', 'It told her to catch fish for him.', 'It taught her how to fish.'], ['do not believe the drawings are old.', 'believe they are allowed to paint there', 'think the drawings should be left alone', 'think the drawings will not disappear'], ['A Dog Named Jessie', 'Love Calmed the Storm', 'Conflicts Between Dogs', 'Fights Between Man and Dog'], [\"Readers'guessing.\", 'Thebasicelementsofthestory.', 'Thesettingofthestory.', 'Theinterrelationshipsbetweenpeopleinthestory.'], ['hopeful', 'strict', 'stubborn', 'helpful'], ['The father used his invention to stop children watching too much TV.', 'It was very bad for the drivers to blow into a bag before their driving.', 'The bike crossing rivers was considered one of the best inventions.', 'The invention of new shoes would make players run much faster.']], 'answer': [1, 0, 3, 3, 3, 3, 1, 1, 3, 0]}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'labels': [1, 0, 3, 3, 3, 3, 1, 1, 3, 0],\n",
       " 'options': [['Ten percent of women who were depressed had depressed partners.',\n",
       "   '2.6 percent of healthy women were depressed.',\n",
       "   'Special attention should be paid to families in which both the father and the mother were depressed.',\n",
       "   \"Primary school children whose parents were both depressed couldn't get along well withtheir peers.\"],\n",
       "  ['Those who love nature.',\n",
       "   'Those who love city life.',\n",
       "   'Those who love the comfort in a fine hotel.',\n",
       "   'Those who love going shopping.'],\n",
       "  ['preparing a dinner for a poor family',\n",
       "   'chatting with the elderly mother and her disabled son',\n",
       "   'making preparations for their own Christmas festival',\n",
       "   'visiting one of their good friends in other district'],\n",
       "  ['red', 'blue', 'green', 'purple'],\n",
       "  ['It told her to swim in the lake.',\n",
       "   'It told her to play by the lake.',\n",
       "   'It told her to catch fish for him.',\n",
       "   'It taught her how to fish.'],\n",
       "  ['do not believe the drawings are old.',\n",
       "   'believe they are allowed to paint there',\n",
       "   'think the drawings should be left alone',\n",
       "   'think the drawings will not disappear'],\n",
       "  ['A Dog Named Jessie',\n",
       "   'Love Calmed the Storm',\n",
       "   'Conflicts Between Dogs',\n",
       "   'Fights Between Man and Dog'],\n",
       "  [\"Readers'guessing.\",\n",
       "   'Thebasicelementsofthestory.',\n",
       "   'Thesettingofthestory.',\n",
       "   'Theinterrelationshipsbetweenpeopleinthestory.'],\n",
       "  ['hopeful', 'strict', 'stubborn', 'helpful'],\n",
       "  ['The father used his invention to stop children watching too much TV.',\n",
       "   'It was very bad for the drivers to blow into a bag before their driving.',\n",
       "   'The bike crossing rivers was considered one of the best inventions.',\n",
       "   'The invention of new shoes would make players run much faster.']],\n",
       " 'article': ['Researchers in London and Bristol have found that men are particularly likely to yield to depression if their partners are also depressed. The finding highlights the importance of paying attention to the partners of depressed mothers, as young children themselves are vulnerable   to social problems if both parents are depressed. Researchers in London and at the University of Bristol launched their study to investigate whether family structure affects the likelihood of depression in men around the time their child is born. They looked at men from traditional families, men with children from a previous relationship, men whose partners had children by a former partner, and men who were not living with their partners. All 7,108 participants filled out a questionnaire on depression, and answered questions about their age, education level and employment status. Details about the quality of their relationships with their partners, networks of friends and previous life events were also recorded. About 3.5 percent of the men and 13 percent of their partners suffered depression around the time their child was born. While men in stepfamilies or who were not living with their partners were twice as likely to get depressed as those in traditional families, this could be explained by other factors that are more common in nontraditional families, such as poor education and relationship conflicts. Even allowing for all these factors, however, the partners of women who were suffering from prenatal   depression were significantly more likely to become depressed themselves, the researchers report in an American journal. Ten percent of women who were depressed had depressed partners. For the healthy women, the figure was only 2.6 percent. Previous research suggests that families with two depressed parents may need special attention. A researcher in Atlanta has found that primary school children with two troubled parents have difficulty relating to their peers. \"It\\'s extremely important to look at the whole family.\" she says. According to the passage, which of the following statements is NOT true?',\n",
       "  \"Don't go to Kauai. Go to any of the other Hawaiian Islands--Maui, Lanai, the Big Island-- but leave Kauai for us. The weather on Kauai is so unpredictable that sometimes it rains all day--in fact, it's the second-wettest spot on the earth. Yes, there are giant double rainbows all the time, and the sunlight through the clouds is magical. But if you are not interested in these, go somewhere else. You just can't control the nature on Kauai, and who wants to surrender   to the nature when you could be at a fine hotel, lying in a comfortable chair next to a swimming pool, with food served upon request?        So what if Kauai produces surf champions the wayprefix = st1 /Texasproduces cowboys? Most of its 300 white-sand beaches are unmarked. Unless you connect with the local people, the hidden spots are hard to find. While Hanalei is the most beautiful town you've ever dreamed of, you can forget about discos and clubs. Worse, it doesn't have one single four-star restaurant. What it does have is the original drive-through places where you pass by a rambutan tree, and pick a piece of fruit.        Shopping in Kauai? Forget it--unless you are interested in shell necklaces and beautifully carved wood bowls. Kauai is not about pampering. It's about going natural and finding the nature within you. It's a do-it-yourself place that offers walking along the coast, diving and swimming in the Pacific Ocean, and lying on the beach.        Don't go to Kauai unless you have a lot of time, because there's only one road, which can be slightly dull. It winds through the beautiful scenery of waterfalls, rivers flowing into the ocean, and taro fields. You have no choice but to look at everything, because the speed limit is 35 m.p.h.        If you're not interested in color1, don't bother with Kauai, because that's what you get--red roads, blue oceans, and a hundred different shades of green. It's like diving on land. Many people on Kauai believe that this is Lemuria--a lost island in the Atlantic. Can you imagine? Those Hawaiians, surfers, New Agers, and people who love nature and beauty and want a different quality of life--what do they know, anyway? Forget about it--you're not going to like it. Go somewhere else. Leave Kauai for us. Who would like to visit Kauai?\",\n",
       "  'Heather Jack and her family, including her two children, usually spend the Christmas holidays preparing a feast--for others to eat. Last Christmas Eve, they went to a house in the neighborhood and prepared a dinner for an elderly woman and her son, who has muscular dystrophy . They stayed for an hour and chatted before heading home to prepare for a visit from Santa  .  \"I think it is that kind of direct experience that many find so meaningful,\" says Heather, president and founder of The Volunteer Family, a Boston-based organization dedicated to matching families with volunteer opportunities, both during the holidays and year-round. \"It\\'s a great way for parents to involve the kids.\" In a holiday season that stretches from before Thanksgiving to just after the New Year, it\\'s nice to hear stories about people with their children giving instead of receiving. Last December Gary and Debra Danoff and their two teenage sons drove to the Washington, D. C. Jewish Community Center(JCC) and spent Christmas morning in the Center\\'s kitchen preparing a feast for homeless shelters.  By choosing to prepare meals for the homeless, the Danoffs bring together a belief in community service with their love of cooking, \"It feels good to prepare food with our kids for other people at Christmas,\" says Gary. \"We want them to know that many people don\\'t have the ability to go to the supermarket and pick the foods they want to eat and pay for them.\" The Danoffs were in good company. Across the city, at least 1000 volunteers with their children went across the region to provide food to the poor people as part of the D. C. JCC\\'s annual \"December 25th Day of Service\", now in its 22nd year. The Heathers did all the following things except_last Christmas Eve.',\n",
       "  \"Monday, April 17 Dear Gramps, I was so upset last week when somebody stole my Super Racer from the park by your house. I called up the toy company but they said they have only red, blue and green racers. Dad called Cobb's Toy Store today and found out they might have purple ones. Can we go there when I come to visit you next week?You and I were only gone for a few minutes to the shop down the street to get ice-cream and cookies. Maybe the thief was watching us. Mum was surprised when I told her the racer was stolen. She said she used to leave things at the park all the time when she was young. Once she even left her bicycle for two days near the swimming pool. Tell Grandma that I like the food she made last time. Ask Grandma if we can have pancakes with sugar for breakfast when I come this time. I have packed in my towel, comb and soap. Tell her this time I won't forget to pack in my toothbrush. Love Toby The writer wants to have a   _   racer.\",\n",
       "  \"On a cold winter day, a fox told Mother Bear that he would teach her how to fish. For she wanted to learn, he took her to a hole in the ice, and told her to put her tail  down into the water. He told her to keep the tail there for a long time. Then when she pulled the tail out of the water, she would find fish around the tail. The bear was foolish enough to believe what the fox said. She sat for a long time with her tail in the water. She was waiting for the fish. But when she tried to pull her tail out of the water she found that it was frozen  in the ice. She asked the fox to pull her out, but the fox laughed to itself and ran away. So she called Father Bear to help her. Father Bear came. He pulled her hard and at last got her out. But a part of her tail was in the ice. That is why people find the bear's tail so short. What did a fox tell Mother Bear to do on a cold winter day?\",\n",
       "  'Tens of thousands of ancient pictures carved into the rocks at one of France\\'s most important tourist sites are being gradually destroyed. Scientists and researchers fear that the 36,000 drawings on rocks in Mont Bego in the French Alps are being damaged so rapidly that they will not survive for future generations. The mountain, believed to have once been a site for prayer, is scattered   with 4,000-year-old drawings cut into bare rock. They include pictures of cows with horns, cultivated fields   and various gods and goddesses. But as the popularity of the site increases, the pictures are being ruined by thoughtless graffiti  . Jean Clottes is the chairman of the International Committee on Rock Art. He says, \"People think that because the pictures have been there so long they will always continue to be there. But if the damage continues at this rate there will be nothing left in 50 years.\" He describes seeing tourists stamping on the drawings, wearing away the rock and definition   of the artwork as they do so. Some visitors, he says, even cut off parts to take home as souvenirs. \"When people think they can\\'t take a good enough photograph, they rub the drawings to get a clearer picture,\" he said. \"The drawings are polished by the weather, and if the sun is shining and the visitors can\\'t see them properly they simply rub them to make them look fresher.\" Other researchers describe how people arrive carrying long sticks with sharp ends to scratch   their own drawings, or even their names, in the rocks. But experts are divided over the best way to preserve the drawings. Henry de Lumley, director of the Museum of Natural History in Paris, believes that the only way to save the site is to turn the whole mountain into a \"no-go\" area, preventing the public from going there except on guided tours. Otherwise, he says, not only will the site be completely destroyed but important research work will be reduced. Clottes disagrees, \"The measure suggested by Henry de Lumley is the most severe, and while it is the most effective, it is also certain to bring about protests from people who live there,\" he said. \"The site was classified as a historic monument years ago by the Ministry of Culture, and we must do as much as possible to save what is there.\" David Lavergne, the regional architect, also wants to avoid closing the site. \"Henry de Lumley\\'s idea isn\\'t ideal,\" he said. \"Our department feels that the best solution is to let people look at the site, but because the area is very big it is difficult to prevent visitors from damaging it. I would prefer that everyone was able to look at it, but the main problem is money. We do not have the funds to employ the necessary number of guards. We may have to consider charging a fee. It doesn\\'t seem to be possible to get the government support.\" In Nice, Annie Echassoux, who also worked on researching the site, is alarmed that as the mountain becomes easier to reach -- tourists can now avoid the three-and-a-half-hour walk by hiring vehicles -- the damage will increase rapidly. She thinks that the only solution is to rope off the area and provide guides. \"You can\\'t say the plan can\\'t go ahead because there is no money,\" she said. \"That is not good enough. Money must be provided because the Ministry of Culture has classified this area as a historic site. If we don\\'t take steps, we will be responsible for losing the drawings for the next generation.\" Jean Clottes says that people who visit the mountain  _  .',\n",
       "  \"They say love can cover a lot of crimes; yet never have I seen it more beautifully showed than in the life of a dog named Jessie. Jessie came into our lives at the age of six months. By that time he had already experienced the hard knocks of life. He was found abandoned on the side of the road, where we adopted him and took him home. From the beginning, it was obvious that Jessie was traumatized  . He was afraid of everything: the car, the doors, the stairs, and just about everything else. We couldn't foresee where Jessie's fear would take us. Jessie was with us for about six months, when we became foster parents to a mixed-breed young dog. Jessie did not like her at all. We all lived in a nervous co-existence, until dinnertime. Within moments a food fight erupted between Jessie and this foster child. It all happened so fast, and I was in the middle. My husband managed to get in between the two dogs, grabbing Jessie by his collar. Jessie screamed all the way down the hall and into the bedroom. I, quickly put the foster dog into her own bedroom and hurried down the hall. The crashing I heard in the bedroom, scared me to death. But nothing prepared me for the scene I witnessed as I opened the bedroom door. There was my husband, on top of a terrified Jessie, holding back his head. Blood dripped from my husband's arm. To tell you the truth, as I was sitting beside my husband in the emergency room, I just didn't know what to do with Jessie. I was so angry at that dog. Day after day, week after week, however, my husband faithfully trained the dog that others would have put down. As his arm healed over the next months, something rare and beautiful began to take place. Jessie, under my husband's gentle persuasion, began to understand and obey. And Jessie adored him. I could see, that although the tempest had ruled Jessie's former life, affirmation and love had calmed the storm. What would be the best title for the text?\",\n",
       "  'The art of reading fiction is largely a matter of inferring meanings. To infer means to understand facts which are not directly stated---only suggested. Inference is one of the commonest ways of knowing things: a child holds his knee and cries; this action implies his feeling; an observer infers that the child is hurt. To infer accurately in everyday life requires caution in observing; to infer skillfully in fiction requires caution in reading; both require disciplined imagination. The short-story reader can expect to find certain basic elements in any story. For example, all stories involve a person or persons, in a particular setting, faced with a demand for a response. The response called for may be a physical action, such as defeating an adversary  or escaping from a danger; or it may be a mental action, such as adjusting to others or within oneself. In either case, the short story is a description in two ways: first, it shows the motives for a given human action; second, it makes a point about the general human situation. Such descriptions, however, rather than being stated directly, usually are implied by the elements of the story. When the reader of a story understands all the facts and their interrelationships, he is ready to infer the significance of the story as a whole---its comment on the human situation. This comment, or theme, is the seed from which the story grew. It is also the idea by which all the separate elements of the story are governed, while these in turn further shape and modify the theme. In addition to action, character, and setting, these elements include structure, mood, tone, and point of view. Fiction reading requires an awareness of all the ways in which a story communicates. It also requires attention to detail. What the author provides is a network of points which serve as clues to his meaning. He invites the reader to develop the meaning by inference, actually to create much of the story himself and so make it part of his own experience. What is inferring in fiction based on?',\n",
       "  \"My parents always raised me to have strong values and hold firm to my confidence in life, and this was never more proved than when a situation arose when it would be easy for most people to ignore it. A gentleman at my father's work smelled awful and neglected his behavior, and as the months went by, he showed signs of confusion. After being told to pick up papers at another building, he would be found sitting at his desk staring at his shoes; after being reminded (to which he would completely believe he hadn't been told the first time), he would be found once again sitting at his desk in the same position. This happened to worsening degrees over a few months and his coworkers either ignored it or were ignorant to this due to a lack of social association with the man. My father began to mentally record all of this and finally sat down with him one day when he was found two hours after work was out, sitting in his car, looking like he didn't know where to go. Apparently the gentleman was in the beginning/middle stages of Alzheimer's and there was someone who used his forgetfulness as a reason to ask him for money every few days. My father took this man to a hospital (for the first time in years) to be properly treated, and then got a caretaker to watch over his condition. He then went to the man's house and helped him sort out all of his financial matters and get his retirement set up; they went to the bank and had a government worker ensure that his bills would be paid for and his children would no longer get to treat him like a personal ATM. That my father took his much personal time to help another man that so many had forgotten or would choose to neglect, or even make fun of, truly shows his character. In the eyes of the author, his father is   _  .\",\n",
       "  'There are some very good inventions which, for one reason or another, don\\'t become popular. These inventions should be better known, even though I think that some of them are crazy. Let\\'s have a look at some of these inventions and see if you agree that they should be more successful. The Australians had a great idea to stop people from drinking and driving. The idea was that if a driver wanted to start the car, she or he would have to blow into a bag first. If there was too much alcohol   in their breath, the car wouldn\\'t start. It sounded like a great idea to me, but people said that they might need to drive the car in an emergency   even if they had drunk too much alcohol. Another idea I liked was an invention by a scientist who thought his children watched too much TV. He connected the TV to an exercise bike so that the electricity to power the TV was produced by the bike. If the children wanted to watch a lot of TV, they had to pedal   very hard. I found another invention on the Internet which encouraged good habits. Believe it or not, this invention was an ashtray   which spoke to you when you lit a cigarette! The \"voice\" of the ashtray was started by the heat from the cigarette and reminded you how dangerous it is to smoke. One of the strangest inventions I have come across is a bicycle which can cross rivers! The idea was that when you came to a river, you could _ a huge plastic ball all around the bike. You would then get into the ball which would float on the river while you pedaled the bike inside the ball! Why not use a bridge instead? A friend of mine at school once bought a strange pair of football shoes. On the bottom of the shoes there was a rotating pad of studs  . The idea was that you would change direction more quickly if the studs rotated with you. The problem was that every time you stopped you changed direction whether you wanted to or not! I think he wore those shoes twice! One thing I would like is a baseball cap with a built-in radio so you can listen to sport all day with your hands free. While we are on the subject of sport, the Americans invented a kind of robot for sports fans. If you were watching your team on TV on your own, you could press a button and the robot would do \"high fives\" with you! Fantastic! I wonder if you have any good ideas for inventions like these. What can we know from the passage?']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_ids = np.random.choice(len(mmlu[\"auxiliary_train\"]), 10, replace=False)\n",
    "print(random_ids)\n",
    "print(mmlu[\"auxiliary_train\"][random_ids])\n",
    "print()\n",
    "merged = merge_mmlu_in_mutual(mutual_plus[\"train\"], mmlu[\"auxiliary_train\"], random_ids)\n",
    "merged[-10:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that tokenization and `DataCollatorWithPadding` work for this mixed type dataset -- MMLU sentences are longer, it\n",
    "likely introduces a lot of `<pad>`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/xqz-u/.cache/huggingface/datasets/lighteval___mutual_harness/mutual_plus/0.0.1/be31c67b35f0d5c4cce450a4e8475f0eb26ae243f5bfd701a524305282b0873a/cache-c112e503a36ca98c.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'options', 'article', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 7098\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_merged = merged.map(\n",
    "    preprocess_mutual,\n",
    "    batched=True,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    ")\n",
    "tokenized_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4, 512]) torch.Size([10])\n",
      "Context: There are some very good inventions which, for one reason or another, don't become popular. These inventions should be better known, even though I think that some of them are crazy. Let's have a look at some of these inventions and see if you agree that they should be more successful. The Australians had a great idea to stop people from drinking and driving. The idea was that if a driver wanted to start the car, she or he would have to blow into a bag first. If there was too much alcohol   in their breath, the car wouldn't start. It sounded like a great idea to me, but people said that they might need to drive the car in an emergency   even if they had drunk too much alcohol. Another idea I liked was an invention by a scientist who thought his children watched too much TV. He connected the TV to an exercise bike so that the electricity to power the TV was produced by the bike. If the children wanted to watch a lot of TV, they had to pedal   very hard. I found another invention on the Internet which encouraged good habits. Believe it or not, this invention was an ashtray   which spoke to you when you lit a cigarette! The \"voice\" of the ashtray was started by the heat from the cigarette and reminded you how dangerous it is to smoke. One of the strangest inventions I have come across is a bicycle which can cross rivers! The idea was that when you came to a river, you could _ a huge plastic ball all around the bike. You would then get into the ball which would float on the river while you pedaled the bike inside the ball! Why not use a bridge instead? A friend of mine at school once bought a strange pair of football shoes. On the bottom of the shoes there was a rotating pad of studs  . The idea was that you would change direction more quickly if the studs rotated with you. The problem was that every time you stopped you changed direction whether you wanted to or not! I think he wore those shoes twice! One thing I would like is a baseball cap with a built-in radio so you can listen to sport all day with your hands free. While we are on the subject of sport, the Americans invented a kind of robot for sports fans. If you were watching your team on TV on your own, you could press a button and the robot would do \"high fives\" with you! Fantastic! I wonder if you have any good ideas for inventions like these. What can we know from the passage?\n",
      "  0 - The father used his invention to stop children watching too much TV.\n",
      "  1 - It was very bad for the drivers to blow into a bag before their driving.\n",
      "  2 - The bike crossing rivers was considered one of the best inventions.\n",
      "  3 - The invention of new shoes would make players run much faster.\n",
      "\n",
      "Ground truth: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<s>There are some very good inventions which, for one reason or another, don\\'t become popular. These inventions should be better known, even though I think that some of them are crazy. Let\\'s have a look at some of these inventions and see if you agree that they should be more successful. The Australians had a great idea to stop people from drinking and driving. The idea was that if a driver wanted to start the car, she or he would have to blow into a bag first. If there was too much alcohol   in their breath, the car wouldn\\'t start. It sounded like a great idea to me, but people said that they might need to drive the car in an emergency   even if they had drunk too much alcohol. Another idea I liked was an invention by a scientist who thought his children watched too much TV. He connected the TV to an exercise bike so that the electricity to power the TV was produced by the bike. If the children wanted to watch a lot of TV, they had to pedal   very hard. I found another invention on the Internet which encouraged good habits. Believe it or not, this invention was an ashtray   which spoke to you when you lit a cigarette! The \"voice\" of the ashtray was started by the heat from the cigarette and reminded you how dangerous it is to smoke. One of the strangest inventions I have come across is a bicycle which can cross rivers! The idea was that when you came to a river, you could _ a huge plastic ball all around the bike. You would then get into the ball which would float on the river while you pedaled the bike inside the ball! Why not use a bridge instead? A friend of mine at school once bought a strange pair of football shoes. On the bottom of the shoes there was a rotating pad of studs . The idea was that you would change direction more quickly if the studs rotated with you. The problem was that every time you stopped you changed direction whether you wanted to or not! I think he wore those shoes twice! One thing I would like is a baseball cap with a built-in radio so you can listen to sport all day with your hands free. While we are on the subject of sport, the Americans invented a kind of robot for sports fans. If you were watching your team on TV on your own, you could press a button and the robot would do \"high fives\" with you! Fantastic! I wonder if you have any good ideas for inventions</s>',\n",
       " '<s>There are some very good inventions which, for one reason or another, don\\'t become popular. These inventions should be better known, even though I think that some of them are crazy. Let\\'s have a look at some of these inventions and see if you agree that they should be more successful. The Australians had a great idea to stop people from drinking and driving. The idea was that if a driver wanted to start the car, she or he would have to blow into a bag first. If there was too much alcohol   in their breath, the car wouldn\\'t start. It sounded like a great idea to me, but people said that they might need to drive the car in an emergency   even if they had drunk too much alcohol. Another idea I liked was an invention by a scientist who thought his children watched too much TV. He connected the TV to an exercise bike so that the electricity to power the TV was produced by the bike. If the children wanted to watch a lot of TV, they had to pedal   very hard. I found another invention on the Internet which encouraged good habits. Believe it or not, this invention was an ashtray   which spoke to you when you lit a cigarette! The \"voice\" of the ashtray was started by the heat from the cigarette and reminded you how dangerous it is to smoke. One of the strangest inventions I have come across is a bicycle which can cross rivers! The idea was that when you came to a river, you could _ a huge plastic ball all around the bike. You would then get into the ball which would float on the river while you pedaled the bike inside the ball! Why not use a bridge instead? A friend of mine at school once bought a strange pair of football shoes. On the bottom of the shoes there was a rotating pad of studs . The idea was that you would change direction more quickly if the studs rotated with you. The problem was that every time you stopped you changed direction whether you wanted to or not! I think he wore those shoes twice! One thing I would like is a baseball cap with a built-in radio so you can listen to sport all day with your hands free. While we are on the subject of sport, the Americans invented a kind of robot for sports fans. If you were watching your team on TV on your own, you could press a button and the robot would do \"high fives\" with you! Fantastic! I wonder if you have any good ideas for inventions</s>',\n",
       " '<s>There are some very good inventions which, for one reason or another, don\\'t become popular. These inventions should be better known, even though I think that some of them are crazy. Let\\'s have a look at some of these inventions and see if you agree that they should be more successful. The Australians had a great idea to stop people from drinking and driving. The idea was that if a driver wanted to start the car, she or he would have to blow into a bag first. If there was too much alcohol   in their breath, the car wouldn\\'t start. It sounded like a great idea to me, but people said that they might need to drive the car in an emergency   even if they had drunk too much alcohol. Another idea I liked was an invention by a scientist who thought his children watched too much TV. He connected the TV to an exercise bike so that the electricity to power the TV was produced by the bike. If the children wanted to watch a lot of TV, they had to pedal   very hard. I found another invention on the Internet which encouraged good habits. Believe it or not, this invention was an ashtray   which spoke to you when you lit a cigarette! The \"voice\" of the ashtray was started by the heat from the cigarette and reminded you how dangerous it is to smoke. One of the strangest inventions I have come across is a bicycle which can cross rivers! The idea was that when you came to a river, you could _ a huge plastic ball all around the bike. You would then get into the ball which would float on the river while you pedaled the bike inside the ball! Why not use a bridge instead? A friend of mine at school once bought a strange pair of football shoes. On the bottom of the shoes there was a rotating pad of studs . The idea was that you would change direction more quickly if the studs rotated with you. The problem was that every time you stopped you changed direction whether you wanted to or not! I think he wore those shoes twice! One thing I would like is a baseball cap with a built-in radio so you can listen to sport all day with your hands free. While we are on the subject of sport, the Americans invented a kind of robot for sports fans. If you were watching your team on TV on your own, you could press a button and the robot would do \"high fives\" with you! Fantastic! I wonder if you have any good ideas for inventions</s>',\n",
       " '<s>There are some very good inventions which, for one reason or another, don\\'t become popular. These inventions should be better known, even though I think that some of them are crazy. Let\\'s have a look at some of these inventions and see if you agree that they should be more successful. The Australians had a great idea to stop people from drinking and driving. The idea was that if a driver wanted to start the car, she or he would have to blow into a bag first. If there was too much alcohol   in their breath, the car wouldn\\'t start. It sounded like a great idea to me, but people said that they might need to drive the car in an emergency   even if they had drunk too much alcohol. Another idea I liked was an invention by a scientist who thought his children watched too much TV. He connected the TV to an exercise bike so that the electricity to power the TV was produced by the bike. If the children wanted to watch a lot of TV, they had to pedal   very hard. I found another invention on the Internet which encouraged good habits. Believe it or not, this invention was an ashtray   which spoke to you when you lit a cigarette! The \"voice\" of the ashtray was started by the heat from the cigarette and reminded you how dangerous it is to smoke. One of the strangest inventions I have come across is a bicycle which can cross rivers! The idea was that when you came to a river, you could _ a huge plastic ball all around the bike. You would then get into the ball which would float on the river while you pedaled the bike inside the ball! Why not use a bridge instead? A friend of mine at school once bought a strange pair of football shoes. On the bottom of the shoes there was a rotating pad of studs . The idea was that you would change direction more quickly if the studs rotated with you. The problem was that every time you stopped you changed direction whether you wanted to or not! I think he wore those shoes twice! One thing I would like is a baseball cap with a built-in radio so you can listen to sport all day with your hands free. While we are on the subject of sport, the Americans invented a kind of robot for sports fans. If you were watching your team on TV on your own, you could press a button and the robot would do \"high fives\" with you! Fantastic! I wonder if you have any good ideas for inventions</s>']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = [\n",
    "    {k: v for k, v in tokenized_merged[-i].items() if k in accepted_keys}\n",
    "    for i in range(1, 11)\n",
    "]\n",
    "example_batch = DataCollatorForMultipleChoice(tokenizer=tokenizer)(example)\n",
    "print(example_batch[\"input_ids\"].shape, example_batch[\"labels\"].shape)\n",
    "\n",
    "show_one_mutual(tokenized_merged[-1])\n",
    "[\n",
    "    tokenizer.decode(example_batch[\"input_ids\"][0][i].tolist())\n",
    "    for i in range(len(example_batch[\"input_ids\"][0]))\n",
    "]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
