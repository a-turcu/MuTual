{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similaraity exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two lists of sentences\n",
    "sentences1 = [\n",
    "    \"The cat sits outside\",\n",
    "    \"A man is playing guitar\",\n",
    "    \"The new movie is awesome\",\n",
    "]\n",
    "sentences2 = [\n",
    "    \"The dog plays in the garden\",\n",
    "    \"A woman watches TV\",\n",
    "    \"The new movie is so great\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 384])\n"
     ]
    }
   ],
   "source": [
    "# Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "print(embeddings1.shape)\n",
    "assert embeddings1.shape == embeddings2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cosine-similarities\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "cosine_scores.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sits outside \t\t The dog plays in the garden \t\t Score: 0.2838\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: -0.0327\n",
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.8939\n"
     ]
    }
   ],
   "source": [
    "# Output the pairs with their score\n",
    "for i in range(len(sentences1)):\n",
    "    print(\n",
    "        \"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(\n",
    "            sentences1[i], sentences2[i], cosine_scores[i][i]\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2838,  0.1310, -0.0029],\n",
       "        [ 0.2277, -0.0327, -0.0136],\n",
       "        [ 0.0543, -0.0502,  0.8939]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank `sentences1` by most similar sentences in `sentences2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([[ 0.2838,  0.1310, -0.0029],\n",
       "        [ 0.2277, -0.0136, -0.0327],\n",
       "        [ 0.8939,  0.0543, -0.0502]]),\n",
       "indices=tensor([[0, 1, 2],\n",
       "        [0, 2, 1],\n",
       "        [2, 0, 1]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# do the ranking\n",
    "ranks = torch.sort(cosine_scores, dim=-1, descending=True)\n",
    "ranks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar sentences to 'The cat sits outside':\n",
      "('The dog plays in the garden', tensor(0.2838))\n",
      "('A woman watches TV', tensor(0.1310))\n",
      "('The new movie is so great', tensor(-0.0029))\n",
      "Delta similarity with rank 1: tensor([0.0000, 0.1527, 0.2866])\n",
      "\n",
      "Most similar sentences to 'A man is playing guitar':\n",
      "('The dog plays in the garden', tensor(0.2277))\n",
      "('The new movie is so great', tensor(-0.0136))\n",
      "('A woman watches TV', tensor(-0.0327))\n",
      "Delta similarity with rank 1: tensor([0.0000, 0.2413, 0.2604])\n",
      "\n",
      "Most similar sentences to 'The new movie is awesome':\n",
      "('The new movie is so great', tensor(0.8939))\n",
      "('The dog plays in the garden', tensor(0.0543))\n",
      "('A woman watches TV', tensor(-0.0502))\n",
      "Delta similarity with rank 1: tensor([0.0000, 0.8396, 0.9441])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diff_with_top = ranks.values[:, 0, None] - ranks.values\n",
    "\n",
    "for i, (val, idx, diff) in enumerate(zip(*ranks, diff_with_top)):\n",
    "    print(f\"Most similar sentences to {sentences1[i]!r}:\")\n",
    "    for v, j in zip(val, idx):\n",
    "        print((sentences2[j], v))\n",
    "    print(f\"Delta similarity with rank 1: {diff}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing: remove speaker roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "read files: 100%|██████████| 886/886 [00:00<00:00, 18149.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<InputExample(context=M: I'm not sure what to order to drink. Beer, white wine or red wine? F: They say red meat go with red wine, light colored meat go with white and oily foods are good with beer. M: I know chicken is white meat., endings=['F: So we should order a bottle of white wine.',\n",
       " 'F: I drank too much white wine and got drunk.',\n",
       " 'F: I didn’t hear you. Please could you tell me again?',\n",
       " 'F: I think we can order beer to go with chicken.'], label=-33, id=test-data/mutual_plus/test/test_543.txt)>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from baseline.multi_choice.utils_multiple_choice import MuTualProcessor\n",
    "from baseline.conf import DATA_DIR\n",
    "\n",
    "p = MuTualProcessor()\n",
    "test_split = p.get_test_examples(DATA_DIR / \"mutual_plus\")\n",
    "test_split[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to keep using the dataset coming together with the repo and the utilities \n",
    "accompanying it, we can simply read examples like in the original code, and simply \n",
    "keep datapoints structure by processing them in memory. `deepcopy` the original \n",
    "object if you don't want to lose it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<InputExample(context=I'm not sure what to order to drink. Beer, white wine or red wine? They say red meat go with red wine, light colored meat go with white and oily foods are good with beer. I know chicken is white meat., endings=['So we should order a bottle of white wine.',\n",
       " 'I drank too much white wine and got drunk.',\n",
       " 'I didn’t hear you. Please could you tell me again?',\n",
       " 'I think we can order beer to go with chicken.'], label=-33, id=test-data/mutual_plus/test/test_543.txt)>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dp in test_split:\n",
    "    dp.inplace_remove_speakers()\n",
    "test_split[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
